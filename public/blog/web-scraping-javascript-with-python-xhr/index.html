<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Web Scraping Javascript with Python | Daniel Michaels</title><meta name=keywords content="python,web"><meta name=description content="Scraping Dynamic Pages with Python Web scraping Python is a great tool for web scraping tasks, it is efficient, easy to read and fast. Whenever looking to grab data from a site, the canonical packages are BeautifulSoup and Requests. Unfortunately, when our target site is dynamically rendered, BeautifulSoup can&rsquo;t &ldquo;see&rdquo; those parts leading to a lot of head scratching. The often touted answer to this is Selenium which spins up a browser thereby rendering the JavaScript making it possible to scrape data from it."><meta name=author content="Daniel Michaels"><link rel=canonical href=https://danielms.site/blog/web-scraping-javascript-with-python-xhr/><meta name=google-site-verification content="XYZabc"><link href=https://danielms.site/assets/css/stylesheet.min.08d6f2005b6ce4ed10207916c0411c66e66f2201e3f7a56e8fb2ccbc4a8b259c.css integrity="sha256-CNbyAFts5O0QIHkWwEEcZuZvIgHj96Vuj7LMvEqLJZw=" rel="preload stylesheet" as=style><link rel=icon href=https://danielms.site/extra/favicon.ico><link rel=icon type=image/png sizes=16x16 href=https://danielms.site/%3Clink%20/%20abs%20url%3E><link rel=icon type=image/png sizes=32x32 href=https://danielms.site/%3Clink%20/%20abs%20url%3E><link rel=apple-touch-icon href=https://danielms.site/%3Clink%20/%20abs%20url%3E><link rel=mask-icon href=https://danielms.site/%3Clink%20/%20abs%20url%3E><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><meta name=generator content="Hugo 0.78.1"><script type=application/javascript>var doNotTrack=false;if(!doNotTrack){window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;ga('create','UA-149607103-1','auto');ga('send','pageview');}</script><script async src=https://www.google-analytics.com/analytics.js></script><meta property="og:title" content="Web Scraping Javascript with Python"><meta property="og:description" content="Scraping Dynamic Pages with Python Web scraping Python is a great tool for web scraping tasks, it is efficient, easy to read and fast. Whenever looking to grab data from a site, the canonical packages are BeautifulSoup and Requests. Unfortunately, when our target site is dynamically rendered, BeautifulSoup can&rsquo;t &ldquo;see&rdquo; those parts leading to a lot of head scratching. The often touted answer to this is Selenium which spins up a browser thereby rendering the JavaScript making it possible to scrape data from it."><meta property="og:type" content="article"><meta property="og:url" content="https://danielms.site/blog/web-scraping-javascript-with-python-xhr/"><meta property="og:image" content="https://danielms.site/105"><meta property="article:published_time" content="2020-03-13T00:00:00+00:00"><meta property="article:modified_time" content="2020-03-13T00:00:00+00:00"><meta property="og:site_name" content="Daniel Michaels"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://danielms.site/105"><meta name=twitter:title content="Web Scraping Javascript with Python"><meta name=twitter:description content="Scraping Dynamic Pages with Python Web scraping Python is a great tool for web scraping tasks, it is efficient, easy to read and fast. Whenever looking to grab data from a site, the canonical packages are BeautifulSoup and Requests. Unfortunately, when our target site is dynamically rendered, BeautifulSoup can&rsquo;t &ldquo;see&rdquo; those parts leading to a lot of head scratching. The often touted answer to this is Selenium which spins up a browser thereby rendering the JavaScript making it possible to scrape data from it."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Web Scraping Javascript with Python","name":"Web Scraping Javascript with Python","description":"Scraping Dynamic Pages with Python Web scraping Python is a great tool for web scraping tasks, it is efficient, easy to read and fast. Whenever looking to grab data from a site, ‚Ä¶","keywords":["python","web"],"articleBody":"Scraping Dynamic Pages with Python Web scraping Python is a great tool for web scraping tasks, it is efficient, easy to read and fast. Whenever looking to grab data from a site, the canonical packages are BeautifulSoup and Requests. Unfortunately, when our target site is dynamically rendered, BeautifulSoup can‚Äôt ‚Äúsee‚Äù those parts leading to a lot of head scratching. The often touted answer to this is Selenium which spins up a browser thereby rendering the JavaScript making it possible to scrape data from it.\nWhile selenium does work it kinda sucks, can be a pain to setup and introduces more complexity. On big projects where scrolling, pagination or link traversal is required you may be best served by using Selenium. Though I would recommend Scrapy, which is excellent and is built for scraping - Selenium is not.\nIn some cases, there is another way.\nAn alternative Many modern web applications render data from third party API‚Äôs or other backend services. When a site uses JavaScript to do this, then we can get a lot of data from it by using only Requests, Postman and cURL.\nThe basic steps:\n find the API endpoint using the browser‚Äôs development tools, copy the URL as a curl command, import that command into postman, checking it works, get postman to auto generate the request into Python code, and plug that into your script, and profit!  This will provide you repeatable python code which will always return a response with the data you require.\nStep 1: Find the URL Let‚Äôs use an example website which uses an XMLHttpRequest pull data from another server and populate a table with stock data.\nAfter navigating to the site, open the development tools and click on the network pane. You may need to refresh the page to populate the network pane with its requests.\nSearching through the requests, we find what we are looking for, in this case the requests are named after the stock symbols. There is no standard but you can filter by XHR in the network pane to make finding juicy targets easier.\nFor the uninitiated, when clicking on the XHR request, select the response pane and look at the JSON data it has returned.\nStep 2: Copy as cURL After finding the appropriate XHR endpoint, we now need to replicate the GET request.\nIn the network tab, as seen above, right click and hover over Copy which will show you an option to Copy as cURL. Selecting this will output something like the following:\ncurl 'https://lic-investing.online/api/stocks/bki' \\ -H 'User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:74.0) Gecko/20100101 Firefox/74.0' \\ -H 'Accept: application/json, text/plain, */*' \\ -H 'Accept-Language: en-US,en;q=0.5' --compressed \\ -H 'DNT: 1' -H 'Connection: keep-alive' \\ -H 'Referer: https://lic-investing.online/' \\ -H 'Pragma: no-cache' \\ -H 'Cache-Control: no-cache' \\ -H 'TE: Trailers' # formatted for easier reading You can test that this works by running the command in your console on MacOS or Linux. On Windows? ü§∑ soz, I don‚Äôt know.\nStep 3: Import into Postman After copying as cURL above, open up Postman.\nIn the top left will be a orange box titled New, and to the right of it will be Import. Select Import and then click on the Paste Raw Text tab. Paste in the cURL command and hit Import. This process should resemble the image below.\nAfter importing the command, Postman will populate all the GET parameters needed to make a request in its main window. Clicking on the blue Send button will fire the request and once Postman receives the response you will see it in the main body of the screen.\nRight now we have returned a JSON object from our target without needing to be on their website proving we can simulate a request from their frontend to the backend. This is how we will scrape the site in a repeatable and reliable way.\nStep 4: Get the python code So far, we‚Äôve created a request to retrieve data from the server. But now we need to turn this request into something we can replicate using Python.\nLet‚Äôs use Postman to automatically generate some Python code for us.\nTo get this auto generated code simply select the Code text block which is directly below the Save drop-down on the right hand side of Postman‚Äôs main screen.\nScroll down to find Python code nicely generated for us. In this example I have chosen Requests, though it also offers http.client as well.\nStep 5: Win Now we have fully functional Python code which can make a request to the endpoint we are targeting and it will return a response as if we were the website. What we do now is pure business logic but the main thing is we did not need to reach for Selenium, and that is worth its weight in code.\nClosing points Be wary of hitting the endpoint repeatedly, you may get black listed by the site. To prevent this, use a library such as Requests-cache. Give them a star if you can!\nThis is also helpful when playing with API‚Äôs which have request or rate limits imposed.\nNot related to XHR but always look over the source of a webpage in a browser, and then contrast that with BeautifulSoup‚Äôs response data. I have had success on React sites by grabbing their Props data that I couldn‚Äôt even see rendered in the browser. To get at custom, hard to scrape data like this, Regex is your friend.\nIf its on the internet, its possible to scrape (within legal limits of course).\n","wordCount":"922","inLanguage":"en","datePublished":"2020-03-13T00:00:00Z","dateModified":"2020-03-13T00:00:00Z","author":{"@type":"Person","name":"Daniel Michaels"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://danielms.site/blog/web-scraping-javascript-with-python-xhr/"},"publisher":{"@type":"Organization","name":"Daniel Michaels","logo":{"@type":"ImageObject","url":"https://danielms.site/extra/favicon.ico"}}}</script></head><body class=single id=top><script>if(localStorage.getItem("pref-theme")==="dark"){document.body.classList.add('dark');}else if(localStorage.getItem("pref-theme")==="light"){document.body.classList.remove('dark')}else if(window.matchMedia('(prefers-color-scheme: dark)').matches){document.body.classList.add('dark');}</script><noscript><style type=text/css>.theme-toggle,.top-link{display:none}</style></noscript><header class=header><nav class=nav><div class=logo><a href=https://danielms.site accesskey=h>Home</a>
<span class=logo-switches><span class=theme-toggle><a id=theme-toggle accesskey=t><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></a></span></span></div><ul class=menu id=menu onscroll=menu_on_scroll()></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Web Scraping Javascript with Python</h1><div class=post-meta>March 13, 2020&nbsp;¬∑&nbsp;5 min&nbsp;¬∑&nbsp;Daniel Michaels</div></header><div class=post-content><h1 id=scraping-dynamic-pages-with-python>Scraping Dynamic Pages with Python<a hidden class=anchor aria-hidden=true href=#scraping-dynamic-pages-with-python>#</a></h1><p><img src=/images/scraping.png alt title="web scraping diagram"></p><h2 id=web-scraping>Web scraping<a hidden class=anchor aria-hidden=true href=#web-scraping>#</a></h2><p>Python is a great tool for web scraping tasks, it is efficient, easy to read and fast. Whenever looking to grab data from a site, the canonical packages are <a href=https://www.crummy.com/software/BeautifulSoup/bs4/doc/>BeautifulSoup</a> and <a href=https://github.com/psf/requests/>Requests</a>. Unfortunately, when our target site is dynamically rendered, BeautifulSoup can&rsquo;t &ldquo;see&rdquo; those parts leading to a lot of head scratching. The often touted answer to this is <a href=https://selenium-python.readthedocs.io/>Selenium</a> which spins up a browser thereby rendering the JavaScript making it possible to scrape data from it.</p><p>While selenium does work it kinda sucks, can be a pain to setup and introduces more complexity. On big projects where scrolling, pagination or link traversal is required you may be best served by using Selenium. Though I would recommend <a href=https://scrapy.org/>Scrapy</a>, which is excellent and is built for scraping - Selenium is not.</p><p>In some cases, there is another way.</p><h2 id=an-alternative>An alternative<a hidden class=anchor aria-hidden=true href=#an-alternative>#</a></h2><p>Many modern web applications render data from third party API&rsquo;s or other backend services. When a site uses JavaScript to do this, then we can get a lot of data from it by using only Requests, <a href=https://www.postman.com/>Postman</a> and <a href=https://curl.haxx.se/>cURL</a>.</p><p>The basic steps:</p><ul><li>find the API endpoint using the browser&rsquo;s development tools,</li><li>copy the URL as a curl command,</li><li>import that command into postman, checking it works,</li><li>get postman to auto generate the request into Python code, and</li><li>plug that into your script, and profit!</li></ul><p>This will provide you repeatable python code which will always return a response with the data you require.</p><h3 id=step-1-find-the-url>Step 1: Find the URL<a hidden class=anchor aria-hidden=true href=#step-1-find-the-url>#</a></h3><p>Let&rsquo;s use an example <a href=https://lic-investing.online>website</a> which uses an <a href=https://en.wikipedia.org/wiki/XMLHttpRequest>XMLHttpRequest</a> pull data from another server and populate a table with stock data.</p><p>After navigating to the site, open the development tools and click on the network pane. You may need to refresh the page to populate the network pane with its requests.</p><p>Searching through the requests, we find what we are looking for, in this case the requests are named after the stock symbols. There is no standard but you can filter by XHR in the network pane to make finding juicy targets easier.</p><p>For the uninitiated, when clicking on the XHR request, select the response pane and look at the JSON data it has returned.</p><p><img src=/images/scrape-net-tab.png alt title="dev tools network tab with json xhr response data"></p><h3 id=step-2-copy-as-curl>Step 2: Copy as cURL<a hidden class=anchor aria-hidden=true href=#step-2-copy-as-curl>#</a></h3><p>After finding the appropriate XHR endpoint, we now need to replicate the GET request.</p><p>In the network tab, as seen above, right click and hover over <em>Copy</em> which will show you an option to <em>Copy as cURL</em>. Selecting this will output something like the following:</p><div class=highlight><pre style=color:#f8f8f2;background-color:#272822;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-sh data-lang=sh>curl <span style=color:#e6db74>&#39;https://lic-investing.online/api/stocks/bki&#39;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;User-Agent: Mozilla/5.0 (X11; Linux x86_64; rv:74.0) Gecko/20100101 Firefox/74.0&#39;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;Accept: application/json, text/plain, */*&#39;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;Accept-Language: en-US,en;q=0.5&#39;</span> --compressed <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;DNT: 1&#39;</span> -H <span style=color:#e6db74>&#39;Connection: keep-alive&#39;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;Referer: https://lic-investing.online/&#39;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;Pragma: no-cache&#39;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;Cache-Control: no-cache&#39;</span> <span style=color:#ae81ff>\
</span><span style=color:#ae81ff></span>-H <span style=color:#e6db74>&#39;TE: Trailers&#39;</span>
<span style=color:#75715e># formatted for easier reading</span>
</code></pre></div><p>You can test that this works by running the command in your console on MacOS or Linux. On Windows? ü§∑ soz, I don&rsquo;t know.</p><h3 id=step-3-import-into-postman>Step 3: Import into Postman<a hidden class=anchor aria-hidden=true href=#step-3-import-into-postman>#</a></h3><p>After copying as cURL above, open up <a href=https://www.postman.com/>Postman</a>.</p><p>In the top left will be a orange box titled <em>New</em>, and to the right of it will be <em>Import</em>. Select <em>Import</em> and then click on the <em>Paste Raw Text</em> tab. Paste in the cURL command and hit <em>Import</em>. This process should resemble the image below.</p><p><img src=/images/scrape-postman.png alt title="Postman import raw text example"></p><p>After importing the command, Postman will populate all the GET parameters needed to make a request in its main window. Clicking on the blue <em>Send</em> button will fire the request and once Postman receives the response you will see it in the main body of the screen.</p><p>Right now we have returned a JSON object from our target without needing to be on their website proving we can simulate a request from their frontend to the backend. This is how we will scrape the site in a repeatable and reliable way.</p><h3 id=step-4-get-the-python-code>Step 4: Get the python code<a hidden class=anchor aria-hidden=true href=#step-4-get-the-python-code>#</a></h3><p>So far, we&rsquo;ve created a request to retrieve data from the server. But now we need to turn this request into something we can replicate using Python.</p><p>Let&rsquo;s use Postman to automatically generate some Python code for us.</p><p>To get this auto generated code simply select the <em>Code</em> text block which is directly below the <em>Save</em> drop-down on the right hand side of Postman&rsquo;s main screen.</p><p>Scroll down to find Python code nicely generated for us. In this example I have chosen Requests, though it also offers <code>http.client</code> as well.</p><p><img src=/images/scrape-python.png alt title="Postman code auto generator example"></p><h3 id=step-5-win>Step 5: Win<a hidden class=anchor aria-hidden=true href=#step-5-win>#</a></h3><p>Now we have fully functional Python code which can make a request to the endpoint we are targeting and it will return a response as if we were the website. What we do now is pure business logic but the main thing is we did not need to reach for Selenium, and that is worth its weight in code.</p><h2 id=closing-points>Closing points<a hidden class=anchor aria-hidden=true href=#closing-points>#</a></h2><p>Be wary of hitting the endpoint repeatedly, you may get black listed by the site. To prevent this, use a library such as <a href=https://github.com/reclosedev/requests-cache>Requests-cache</a>. Give them a star if you can!</p><p>This is also helpful when playing with API&rsquo;s which have request or rate limits imposed.</p><p>Not related to XHR but always look over the source of a webpage in a browser, and then contrast that with BeautifulSoup&rsquo;s response data. I have had success on React sites by grabbing their Props data that I couldn&rsquo;t even see rendered in the browser. To get at custom, hard to scrape data like this, Regex is your friend.</p><p>If its on the internet, its possible to scrape (within legal limits of course).</p></div><footer class=post-footer><ul class=post-tags><li><a href=https://danielms.site/tags/python>python</a></li><li><a href=https://danielms.site/tags/web>web</a></li></ul><div class=share-buttons><a target=_blank rel="noopener noreferrer" aria-label="share Web Scraping Javascript with Python on twitter" href="https://twitter.com/intent/tweet/?text=Web%20Scraping%20Javascript%20with%20Python&url=https%3a%2f%2fdanielms.site%2fblog%2fweb-scraping-javascript-with-python-xhr%2f&hashtags=python%2cweb"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-253.927 424.544c135.939.0 210.268-112.643 210.268-210.268.0-3.218.0-6.437-.153-9.502 14.406-10.421 26.973-23.448 36.935-38.314-13.18 5.824-27.433 9.809-42.452 11.648 15.326-9.196 26.973-23.602 32.49-40.92-14.252 8.429-30.038 14.56-46.896 17.931-13.487-14.406-32.644-23.295-53.946-23.295-40.767.0-73.87 33.104-73.87 73.87.0 5.824.613 11.494 1.992 16.858-61.456-3.065-115.862-32.49-152.337-77.241-6.284 10.881-9.962 23.601-9.962 37.088.0 25.594 13.027 48.276 32.95 61.456-12.107-.307-23.448-3.678-33.41-9.196v.92c0 35.862 25.441 65.594 59.311 72.49-6.13 1.686-12.72 2.606-19.464 2.606-4.751.0-9.348-.46-13.946-1.38 9.349 29.426 36.628 50.728 68.965 51.341-25.287 19.771-57.164 31.571-91.8 31.571-5.977.0-11.801-.306-17.625-1.073 32.337 21.15 71.264 33.41 112.95 33.41z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Web Scraping Javascript with Python on linkedin" href="https://www.linkedin.com/shareArticle?mini=true&url=https%3a%2f%2fdanielms.site%2fblog%2fweb-scraping-javascript-with-python-xhr%2f&title=Web%20Scraping%20Javascript%20with%20Python&summary=Web%20Scraping%20Javascript%20with%20Python&source=https%3a%2f%2fdanielms.site%2fblog%2fweb-scraping-javascript-with-python-xhr%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM160.461 423.278V197.561h-75.04v225.717h75.04zm270.539.0v-129.439c0-69.333-37.018-101.586-86.381-101.586-39.804.0-57.634 21.891-67.617 37.266v-31.958h-75.021c.995 21.181.0 225.717.0 225.717h75.02v-126.056c0-6.748.486-13.492 2.474-18.315 5.414-13.475 17.767-27.434 38.494-27.434 27.135.0 38.007 20.707 38.007 51.037v120.768h75.024zm-307.552-334.556c-25.674.0-42.448 16.879-42.448 39.002.0 21.658 16.264 39.002 41.455 39.002h.484c26.165.0 42.452-17.344 42.452-39.002-.485-22.092-16.241-38.954-41.943-39.002z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Web Scraping Javascript with Python on reddit" href="https://reddit.com/submit?url=https%3a%2f%2fdanielms.site%2fblog%2fweb-scraping-javascript-with-python-xhr%2f&title=Web%20Scraping%20Javascript%20with%20Python"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zM446 265.638c0-22.964-18.616-41.58-41.58-41.58-11.211.0-21.361 4.457-28.841 11.666-28.424-20.508-67.586-33.757-111.204-35.278l18.941-89.121 61.884 13.157c.756 15.734 13.642 28.29 29.56 28.29 16.407.0 29.706-13.299 29.706-29.701.0-16.403-13.299-29.702-29.706-29.702-11.666.0-21.657 6.792-26.515 16.578l-69.105-14.69c-1.922-.418-3.939-.042-5.585 1.036-1.658 1.073-2.811 2.761-3.224 4.686l-21.152 99.438c-44.258 1.228-84.046 14.494-112.837 35.232-7.468-7.164-17.589-11.591-28.757-11.591-22.965.0-41.585 18.616-41.585 41.58.0 16.896 10.095 31.41 24.568 37.918-.639 4.135-.99 8.328-.99 12.576.0 63.977 74.469 115.836 166.33 115.836s166.334-51.859 166.334-115.836c0-4.218-.347-8.387-.977-12.493 14.564-6.47 24.735-21.034 24.735-38.001zm-119.474 108.193c-20.27 20.241-59.115 21.816-70.534 21.816-11.428.0-50.277-1.575-70.522-21.82-3.007-3.008-3.007-7.882.0-10.889 3.003-2.999 7.882-3.003 10.885.0 12.777 12.781 40.11 17.317 59.637 17.317 19.522.0 46.86-4.536 59.657-17.321 3.016-2.999 7.886-2.995 10.885.008 3.008 3.011 3.003 7.882-.008 10.889zm-5.23-48.781c-16.373.0-29.701-13.324-29.701-29.698.0-16.381 13.328-29.714 29.701-29.714 16.378.0 29.706 13.333 29.706 29.714.0 16.374-13.328 29.698-29.706 29.698zm-160.386-29.702c0-16.381 13.328-29.71 29.714-29.71 16.369.0 29.689 13.329 29.689 29.71.0 16.373-13.32 29.693-29.689 29.693-16.386.0-29.714-13.32-29.714-29.693z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Web Scraping Javascript with Python on facebook" href="https://facebook.com/sharer/sharer.php?u=https%3a%2f%2fdanielms.site%2fblog%2fweb-scraping-javascript-with-python-xhr%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512H342.978v-192.915h66.6l12.672-82.621h-79.272v-53.617c0-22.603 11.073-44.636 46.58-44.636H425.6v-70.34s-32.71-5.582-63.982-5.582c-65.288.0-107.96 39.569-107.96 111.204v62.971h-72.573v82.621h72.573V512h-191.104c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Web Scraping Javascript with Python on whatsapp" href="https://api.whatsapp.com/send?text=Web%20Scraping%20Javascript%20with%20Python%20-%20https%3a%2f%2fdanielms.site%2fblog%2fweb-scraping-javascript-with-python-xhr%2f"><svg viewBox="0 0 512 512"><path d="M449.446.0C483.971.0 512 28.03 512 62.554v386.892C512 483.97 483.97 512 449.446 512h-386.892c-34.524.0-62.554-28.03-62.554-62.554v-386.892c0-34.524 28.029-62.554 62.554-62.554h386.892zm-58.673 127.703c-33.842-33.881-78.847-52.548-126.798-52.568-98.799.0-179.21 80.405-179.249 179.234-.013 31.593 8.241 62.428 23.927 89.612l-25.429 92.884 95.021-24.925c26.181 14.28 55.659 21.807 85.658 21.816h.074c98.789.0 179.206-80.413 179.247-179.243.018-47.895-18.61-92.93-52.451-126.81zM263.976 403.485h-.06c-26.734-.01-52.954-7.193-75.828-20.767l-5.441-3.229-56.386 14.792 15.05-54.977-3.542-5.637c-14.913-23.72-22.791-51.136-22.779-79.287.033-82.142 66.867-148.971 149.046-148.971 39.793.014 77.199 15.531 105.329 43.692 28.128 28.16 43.609 65.592 43.594 105.4-.034 82.149-66.866 148.983-148.983 148.984zm81.721-111.581c-4.479-2.242-26.499-13.075-30.604-14.571-4.105-1.495-7.091-2.241-10.077 2.241-2.986 4.483-11.569 14.572-14.182 17.562-2.612 2.988-5.225 3.364-9.703 1.12-4.479-2.241-18.91-6.97-36.017-22.23-13.314-11.876-22.304-26.542-24.916-31.026s-.279-6.908 1.963-9.14c2.016-2.007 4.48-5.232 6.719-7.847 2.24-2.615 2.986-4.484 4.479-7.472 1.493-2.99.747-5.604-.374-7.846-1.119-2.241-10.077-24.288-13.809-33.256-3.635-8.733-7.327-7.55-10.077-7.688-2.609-.13-5.598-.158-8.583-.158-2.986.0-7.839 1.121-11.944 5.604-4.105 4.484-15.675 15.32-15.675 37.364.0 22.046 16.048 43.342 18.287 46.332 2.24 2.99 31.582 48.227 76.511 67.627 10.685 4.615 19.028 7.371 25.533 9.434 10.728 3.41 20.492 2.929 28.209 1.775 8.605-1.285 26.499-10.833 30.231-21.295 3.732-10.464 3.732-19.431 2.612-21.298-1.119-1.869-4.105-2.99-8.583-5.232z"/></svg></a><a target=_blank rel="noopener noreferrer" aria-label="share Web Scraping Javascript with Python on telegram" href="https://telegram.me/share/url?text=Web%20Scraping%20Javascript%20with%20Python&url=https%3a%2f%2fdanielms.site%2fblog%2fweb-scraping-javascript-with-python-xhr%2f"><svg viewBox="2 2 28 28"><path d="M26.49 29.86H5.5a3.37 3.37.0 01-2.47-1 3.35 3.35.0 01-1-2.47V5.48A3.36 3.36.0 013 3 3.37 3.37.0 015.5 2h21A3.38 3.38.0 0129 3a3.36 3.36.0 011 2.46V26.37a3.35 3.35.0 01-1 2.47A3.38 3.38.0 0126.49 29.86zm-5.38-6.71a.79.79.0 00.85-.66L24.73 9.24a.55.55.0 00-.18-.46.62.62.0 00-.41-.17q-.08.0-16.53 6.11a.59.59.0 00-.41.59.57.57.0 00.43.52l4 1.24 1.61 4.83a.62.62.0 00.63.43.56.56.0 00.4-.17L16.54 20l4.09 3A.9.9.0 0021.11 23.15zM13.8 20.71l-1.21-4q8.72-5.55 8.78-5.55c.15.0.23.0.23.16a.18.18.0 010 .06s-2.51 2.3-7.52 6.8z"/></svg></a></div></footer></article></main><footer class=footer><span>&copy; 2020 <a href=https://danielms.site>Daniel Michaels</a></span>
<span>&#183;</span>
<span>Powered by <a href=https://gohugo.io/ rel="noopener noreferrer" target=_blank>Hugo</a></span>
<span>&#183;</span>
<span>Theme <a href=https://git.io/hugopapermod rel=noopener target=_blank>PaperMod</a></span></footer><a href=#top aria-label="go to top" title="Go to Top" accesskey=g><button class=top-link id=top-link type=button><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6"><path d="M12 6H0l6-6z"/></svg></button></a>
<script defer src=https://danielms.site/assets/js/highlight.min.27cd435cc9ed6abb4b496581b151804f79f366c412620272bb94e2f5f598ebcc.js integrity="sha256-J81DXMntartLSWWBsVGAT3nzZsQSYgJyu5Ti9fWY68w=" onload=hljs.initHighlightingOnLoad();></script><script>window.onload=function(){if(localStorage.getItem("menu-scroll-position")){document.getElementById('menu').scrollLeft=localStorage.getItem("menu-scroll-position");}}
document.querySelectorAll('a[href^="#"]').forEach(anchor=>{anchor.addEventListener("click",function(e){e.preventDefault();var id=this.getAttribute("href").substr(1);document.querySelector(`[id='${decodeURIComponent(id)}']`).scrollIntoView({behavior:"smooth"});});});var mybutton=document.getElementById("top-link");window.onscroll=function(){if(document.body.scrollTop>800||document.documentElement.scrollTop>800){mybutton.style.visibility="visible";mybutton.style.opacity="1";}else{mybutton.style.visibility="hidden";mybutton.style.opacity="0";}};function menu_on_scroll(){localStorage.setItem("menu-scroll-position",document.getElementById('menu').scrollLeft);}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{if(document.body.className.includes("dark")){document.body.classList.remove('dark');localStorage.setItem("pref-theme",'light');}else{document.body.classList.add('dark');localStorage.setItem("pref-theme",'dark');}})</script></body></html>